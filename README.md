![STRX](https://github.com/Phuire-Research/STRX/blob/main/STRX.png?raw=true)
#### *The Unified Turing Machine - Plain Text Intelligence of Doing in the Spirit of the Open Internet*
*Note if you notice a strange set of capitalizations of concepts, this is a new format that is being formalized as conceptual logic. In addition, there was no generative intelligence used in the creation of this framework. This is **100% hand written.***

----
![Tests](https://github.com/Phuire-Research/STRX/actions/workflows/node.js.yml/badge.svg)
### Abstract
One of the greatest gaps of understanding in the modern age is whether what we speak has some mechanical bearing, or is just some statistical output. What the Unified Turing Machine, and by extension STRX accomplishes is to make plain the unifying aspect of the unknown mechanics of language. This is accomplished via logical verbose descriptions that are unified by code implementations and proved via a test. That currently we have trouble distinguishing logic from opinion in our speech, thus this approach seeks to prove a distinction between speech that is testable versus not. As we are currently in the age of post truth and such would only be magnified without some test due to the advent of Ai. Where we can describe logically the exact process that would transform some data into something else in our very speech. Then back that description up with a code implementation that accomplishes the transformation. There is backing to this in the original Unified Science International Encyclopedia, via its entry on the "Foundations of Logic and Mathematics." But in the current generalized scope, there had been no further pursuit to understand the unifying aspect of language and mathematics. And colloquially are presented as if they are completely separate concepts. Yet mathematics is just one aspect of programming, we formalize mainly through logic and describe our functions and variables via names. Therefore programming is a fundamentally unified format that may be used to prove sound verbose logic.

This is to find a solution to the age of post truth, where the increase of productivity that Ai represents would magnify this effect. As language that does not support truth, would be logically inconsistent and therefore placed within opinion as it would be untestable. That there can be decisions made that have some backing via sound logic that can be independent from the knowledge we are taught. "Where we can have precise measurements and be bothered when a ruler's mark is slightly off." As all of this is the observation of qualities that are useful to us. And that is the very function of this framework. We organize by concepts, describe their qualities logically by their functionality, and test their implementations via code. Further this framework makes mundane the higher orders of logic that are currently obfuscated in the given frame of humanity. Via a direct demonstration of steps and how we can account for decisions between these steps in the process of transforming some data. Or simply how we can prove a point logically in a testable fashion, versus the absolute need of referencing to back up opinion. As that is still just an informed opinion, versus logic.

The inspiration for STRX was that of Redux and its origin via the FLUX design pattern of a finite state machine, and is instead designed to act as an abstract graph computer. While maintaining several similarities for the sake of familiarity of that pattern of design for developers. While offering enough of a departure where the traditional store is now referred to as the **Axium**. Where an axium is a set of concepts that are unified to form a greater conceptualization. Namely that of your application, but in contrast to its inspiration and accomplished by the ActionStrategy design pattern. Which is a blunt demonstration of higher order logic, that allows qualities of other concepts to be used/unified together to perform some transformation. And further enhanced via the spatial ownership paradigm, that relays to the one universal concept that is plain. That all things in space, have a position, and we may respect that position to allow multiple ActionStrategies to be ran concurrently. Without race conditions within any given size network. Noting that despite the utilization of actions there are no string type comparisons beyond the initial creation for the sake of performance. This allows us to actively encouraging to cross the streams of state, or to be specific that of the unifying concepts and their qualities. To create an application that is greater than the sum of its parts due to its composability.

![Ghostbusters - "We'll Cross the Streams" - (HD) - Scenes from the 80s - (1984)](https://github.com/Phuire-Research/STRX/blob/main/CrossTheStreams.gif?raw=true)

### Concept Index
* [Action Strategy](https://github.com/Phuire-Research/STRX/blob/main/ActionStrategy.md) - Created in 2018, this is the governing concept that allows for the Unified Turing Machine to have a strong halting quality. Likewise the direct analog of higher order logic and universal transformer.
* [Axium](https://github.com/Phuire-Research/STRX/blob/main/Axium.md) - Governing concept that contains the set of concepts that formalizes each axium.
* [Concept](https://github.com/Phuire-Research/STRX/blob/main/Concept.md) - The programming abstraction of a concept that is decomposable to the sum of its parts via: state, qualities, principles, and mode.
* [Stage Planner](https://github.com/Phuire-Research/STRX/blob/main/StagePlanner.md) - Introducing the stage planner paradigm. A specialized helper function to prevent action overflow when dispatching actions in subscriptions.
* [Action Controller](https://github.com/Phuire-Research/STRX/blob/main/ActionController.md) - Allows methods to be performed asynchronously.
* [Spatial Ownership](https://github.com/Phuire-Research/STRX/blob/main/SpatialOwnership.md) - Streamlines the complex nature of the ActionStrategy as it relates to itself and other axiums. This is what allows STRX to be a graph computation paradigm.
* [Strategy Data](https://github.com/Phuire-Research/STRX/blob/main/StrategyData.md) - Allows for the ActionStrategy pattern to act as a "Universal Transformer." Likewise decorates strategies with the necessary information to inform "ActionNodes," of possible failure conditions.
* [Unified Turing Machine](https://github.com/Phuire-Research/STRX/blob/main/The-Unified-Turing-Machine.md) - The governing concept for this entire framework.

## The Halting Problem
* [Video Citation: The requirement to stop within a behavior tree. Artificial Intelligence Summit @GDC 2016 via Youtube](https://youtube.com/clip/UgkxtZlIbvaMv0OUCJ5kJFiaUCjmEQCBD0C6?si=tkrAkvbpqByq096U)

Noting that in the clip above, the speaker is using behavior trees and the stopping term. Here within STRX, a behavior tree would be an ActionStrategy that is dispatched via a staged "Plan." What separates STRX from the approach above is that we are using the finite state machine pattern to avoid the use of the infinitely looping check of some observed value. In addition we are referring to this as halting.

As the ability to halt within an intelligent system is the demonstration of its logical consistency. This can be directly determined via a systems generation of hallucinations and misinformation. A intelligent system that is capable of halting, would likewise be capable of determining if it can satisfy some input, without providing a generalized answer that appears to solve that output. There is strength in the ability to recognize the possibility of some solution within these hallucinations, but likewise the ability to recognize such would be an additional ability to halt. Would merely be, "I do not know how to solve that problem with what's available, but if I had access to these features I could solve that problem."

## How STRX Solves this Problem
Further the Unified Turing also accomplishes what has been considered to be an impossible to solve problem of the original theoretical Turing Machine. The halting problem, this is accomplished via the finite state machine pattern in conjunction with the new ActionStrategy pattern. This new pattern is capable of representing any calculation, but must be designed with a conclusion. Thus the finite state machine of STRX can perform any calculation and halts upon their conclusion. Noting that here we are using logic to solve this and utilizing a set of specified requirements to have said solution. The primary requirement to satisfy the solution is that the main run time of a program, must be a recursive function. The ActionStrategy pattern in addition satisfies the next requirement, via being a specific set of instruction that concludes, but is capable of a branching behavior that affords for error correction. The specific interest in presenting this solution at this time is to demonstrate a method of safety as to disallow some run away effect from an Artificial Intelligence or Neural Network.

As this pattern of halting is designed to be an analog to the inner workings of some graph network that eventually has some output. This is noting that previous to 2023, one of the major problem behind LLMs is whether they would have an output due to some input. Or even as the result of fine tuning when a stop token wouldn't ordinarily be required within the data set. [Video Citation: QLoRA is all you need @sentdex via Youtube](https://youtube.com/clip/Ugkx47h3s4gtOSrKxF-CdqsnTrPTWwnwwha8?si=VLQJSBoZDw0dYsCF) That we may compare the runtime of an ActionStrategy to a Neural Network, would represent a series of weighted sums that fails to halt in aggregate and bears no output, or a repeating output. [LLM Infinite Loops & Failure Modes: The Current State of LLM Extraction @GDELT via Medium](https://blog.gdeltproject.org/llm-infinite-loops-failure-modes-the-current-state-of-llm-entity-extraction/) In addition this likewise demonstrates a method of proving safe functionality of any new Ai systems in their ability to halt. As if we task some Ai to create paperclips, how would we analyze their strategies to demonstrate that they would not paperclip the entire universe? That their strategies should be proven to be able to halt once some condition is met.

Likewise the unfortunate truth of a Unified Turing Machine due to its recursive functionality. Is that it requires the ability to halt to function as a hard requirement. Otherwise the developer will run into unexpected behavior in their applications. This would be due to strategies and/or the supporting framework are halting incomplete and experiencing action overflow. As our general good enough computers and their branch prediction will generate ghost actions and other unexpected behaviors during this condition. Such as the thrashing the applications memory, and the inability to receive some output akin to a unresponsive Neural Network. So by strange effect the solution to solve the halting problem, was a method of programming that went beyond data entry of classic. Utilizing logic over mathematics to create the scope of this framework, to afford for the dynamic functionality of data transformation versus data entry.

Or simply, due to the recursive functionality of STRX, that requires the ability to halt by design. Is accomplished via ActionStrategies, that perform higher order logic within the finite state machine that is the axium. That describes the exact steps to accomplish something. As every ActionStrategy has a conclusion, and can represent any calculation. This is the advent of "Logical Determinism," is the logical ability to disclude calculations and their associated symbols/qualities that do not halt. As ActionStrategies represent a finite selection of symbols organized by a branching sequence that can be tested to be halting complete. And are chosen not by symbol selection, but determined via the positional load of said symbols within this system.
### The Testable Proof
```typescript
// ./src/test/ownership.test.ts
const orderOfTopics: string[] = [];
let finalRun = true;
const axium = createAxium('ownershipTest', [
  createOwnershipConcept(),
  createCounterConcept(),
  createExperimentConcept(createExperimentActionQueState(), [checkInStrategyQuality], [experimentActionQuePrinciple])
], true, true);
const plan = axium.stage(
  'Testing Ownership Staging', [
    (cpts, dispatch) => {
      const axiumState = cpts[0].state as AxiumState;
      if (axiumState.lastStrategy === setOwnerShipModeTopic) {
        const ownership = selectState<OwnershipState>(cpts, ownershipName);
        console.log('Stage 1', ownership.ownershipLedger, ownership.pendingActions);
        const counter = selectState<Counter>(cpts, counterName);
        console.log('Count: ', counter.count);
        // This will place a counting strategy in the experiment actionQue to be later dispatched.
        //    Via its principle, to simulate an action moving off premise.
        dispatch(strategyBegin(puntCountingStrategy()), {
          iterateStage: true
        });
      }
    },
    // Comment out if testing log and the halting quality of the Unified Turing Machine.
    (cpts, dispatch) => {
      // Will be ran after both counting strategies conclude.
      const ownership = selectState<OwnershipState>(cpts, ownershipName);
      console.log('Stage 2', ownership.ownershipLedger, ownership.pendingActions);
      dispatch(counterSetCount({newCount: 1000}, undefined, 7000), { iterateStage: true});
    },
    (cpts, dispatch) => {
      const ownership = selectState<OwnershipState>(cpts, ownershipName);
      console.log('Stage 3', ownership.ownershipLedger, ownership.pendingActions);
      const counter = selectState<Counter>(cpts, counterName);
      console.log('Count: ', counter.count);
      dispatch(strategyBegin(experimentPrimedCountingStrategy(cpts)), {
        iterateStage: true
      });
    },
    (cpts, dispatch) => {
      const axiumState = cpts[0].state as AxiumState;
      const counter = selectState<Counter>(cpts, counterName);
      console.log('Stage 4', axiumState.lastStrategy, orderOfTopics);
      if (orderOfTopics.length === 2 && finalRun) {
        finalRun = false;
        // This will be the final test to be triggered by a log action.
        console.log('Stage 3, If #3 | Count: ', counter.count, orderOfTopics);
        expect(orderOfTopics[0]).toBe(experimentCountingTopic);
        expect(counter.count).toBe(3);
        // Comment in if testing the halting ability of log and setCount stage is commented out.
        // setTimeout(() => {done();}, 1000);
        plan.conclude();
      } else if (
        (axiumState.lastStrategy === experimentCountingTopic ||
        axiumState.lastStrategy === experimentPrimedCountingTopic) &&
        orderOfTopics.length === 0) {
        console.log('Stage 3, If #1 | Count: ', counter.count);
        orderOfTopics.push(axiumState.lastStrategy);
      } else if (
        (axiumState.lastStrategy === experimentCountingTopic ||
        axiumState.lastStrategy === experimentPrimedCountingTopic) &&
        orderOfTopics.length === 1) {
        if (orderOfTopics[0] !== axiumState.lastStrategy) {
          console.log('Stage 3, If #2 | Count: ', counter.count);
          orderOfTopics.push(axiumState.lastStrategy);
          // Due to the halting behavior of a Unified Turing Machine, this will trigger before set Count at step 2.
          //  If commented out, set Count will trigger the the "If #3" check.
          //  If commenting out setCount stage, disable the test in the subscription
          //    Then be sure to enabled the final done check in "If #3".
          //    Then enabling the axiumLog dispatch will allow the test to conclude.
          //    But disabling the axiumLog will never trigger the "If #3" check and disallow the test to conclude.
          //      This proves STRX as a Unified Turing Machine and this configuration Halting Complete.
          dispatch(axiumLog(), {
            runOnce: true
          });
        }
      }
    }
  ]);
const sub = axium.subscribe((concepts: Concept[]) => {
  const state = selectState<OwnershipState>(concepts, ownershipName);
  const _axiumState = concepts[0].state as AxiumState;
  if (state.initialized && _axiumState.lastStrategy === setOwnerShipModeTopic) {
    expect(state.initialized).toBe(true);
  }
  const counter = selectState<Counter>(concepts, counterName);
  // This will run last, despite setCount being the second staged dispatch.
  if (counter.count >= 1000) {
    console.log('Subscription, Final Count: ', counter.count, orderOfTopics);
    expect(counter.count).toBe(1000);
    // Comment out if setCount stage is disabled and instead testing axiumLogs of "If #2" halting interaction.
    setTimeout(() => {done();}, 1000);
    sub.unsubscribe();
    axium.close();
  }
});
```
the above demonstrates two solutions. one of the ability to network axiums together unlike the design of flux that would restrict all calculations to a singular source of truth. that is accomplished via the ownership pattern and halts upon multiple concluding strategies that would have some race condition within the network. the second would be the comments to demonstrate the power of a finite state machine and its ability to return some output that can be logically determined. noting the comment selections. this is presented as such to provide a testable back and forth with the developer to inform some intuition as to strx's inner workings.

### strx - *st*rategic *r*eactive(x) framework
strx is the graph computational framework release of a new unified turing machine. the internal structure of this machine directly relays to a form of written intelligence of doing, over that of knowledge retrieval, and data entry. but may be written to facilitate any preexisting paradigm such as that same expert system paradigm of classic. the importance of this machine to the now of 2023, is the functionality of the actionstrategy pattern as it relays to human and machine intelligence. as the pattern itself is a unified set of logical explanations of doing as a series of functions. unified to the mechanism of that doing via code implementations of that logical explanation. we organize using concepts as it relays to a historic pursuit of unifying all fields of science in addition to a logical explanation. and is the comparable comparison to a graph of machine learning universal functions, and the generated neural network of layers that aggregate to greater universal functions. the comparison to that of llm, during runtime these actions are outputted to an actionlist that is later composed as a strx sentence.

#### the anatomy of a strx sentence
```
preposition(/+)decision + body + denoter
example: Finally + Open Axium + to Notify Subscribers of State changes.
```
This allows for a STRX Dialog to be constructed in the same formalization of that of a paragraph. Where the strategy topic is the literal topic sentence of a paragraph. And is followed by all steps and possible decision that create a unified paragraph.
```
TOPIC + SENTENCE + SENTENCE + SENTENCE
Example: 
Axium Initialization Strategy. +
Begin with register Axium Action and Concept Streams. +
Then initialize Principles and set new Subscribers to General Subscribers list. +
Next set Axium to its current Default Mode Index. +
Finally Open Axium to Notify Subscribers of State changes.
```

Where the main difference between that of a traditional paragraph and the compositional structure of the STRX ActionStrategy. Is that these STRX paragraphs are capable of representing different decisions via calculations that inform the final output of that paragraph and its sentences. This can be likened to some high orders of logic via decisions made within the context of an ActionStrategy. Except in contrast to current understanding of higher order logic. It is a direct blunt mapping of these higher order conventions versus some nested obtuse nightmare. But likewise exponentially grows in complexity the longer the ActionStrategy. This is the consequence and relationship of binary/N trees and the exponential quality of their branches quantified. The difference traditionally ignored here, is that we can logical trim branches. And majority of ActionStrategies will be of some sequential flow and short running in their life times.

#### STRX - Axium Flow Diagram 
```
Action -> Mode -> Method --> Action.Strategy ? Halt : -> Next Action --> Mode
               |                                                      |
               -> Reducer -> Concept[] -------------------------------|
                                       |                              |
                    Construct Emission -> Principle -> Action ------->|
                       *Mode Can Block |*> External -> Action ------->|
                                     Axium/Client/Server
```
To satisfy the requirements of a Unified Turing Machine, the axium is the entire recursive functionality that contains a set of concepts. That can transform its functionality via its mode, that actualizes the loaded concept qualities from the dispatched action. If the action has an ActionStrategy attached, then that the method emits the next action based on some decision. While the reducer informs of any new state changes to be supplied back into the concept stream and the subscribers of that change.

In addition, principles here act as a containing observer that allows for utilization of preexisting constructs. Which are applications/framework/libraries that cannot be decomposed to the sum of their parts and would have to indirectly interact with the action stream. To maintain some relevant functionality within the axium. The principles are subscribed to the inner concept[] stream. And can supply or emit values to and from that construct, such as interface with an application. Or even that of outside observations such as an API, or any external process.

## STRX was Designed Specifically to Mirror the Functionality of Neural Networks to Decompose their Black Box Universal Functions.
![Fourier Universal Function, Credit to Emergent Garden @Youtube](https://github.com/Phuire-Research/STRX/blob/main/fourierUniversalFunction-CC-Emergent-Garden.png?raw=true)
The above would be some Neural Network's universal function made to fit some unknown function via a fourier transform. If we know the function ahead of the time we may set the weights specifically to represent that function. The question that is obfuscated in current understanding is by what mechanism is this Neural Network choosing the next node on the graph to determine its output? As the decision is obfuscated by the weighted sum between each layer of the Neural Network.

![Neural Network Diagram](https://github.com/Phuire-Research/STRX/blob/main/NeuralNetwork.png?raw=true)
This is the reason for STRX's recursive functionality. Is that the life time of an ActionStrategy is the exact point of comparison between that of a set of universal functions on a graph and the weighted sum between each layer in the graph above. But direct and without the need to calculate the others nodes in the network. As the method allows for the next node to be some logical deterministic instruction via its method. But the entire function is the net run time of that action through the axium's mode. As the mode is just a function that relays to composition of functions that satisfy the quality of an action to it's reducer and method dictated by the ActionStrategy. Keep in mind a function is allowed to be composed of functions. Therefore what is obfuscated within networks, is not only the function themselves, but the decisions made between the Neural Networks layers that control the final output by weighted sum, based on some input. Except here the mode can be represented as a singular universal function or node, that does not have to rely on the sum of weights to divine a weighted sum to inform its output. And is instead direct and in plain text in the spirit of the open internet.

This is what allows for STRX to act as a comparable mirror to that of a Neural Network, while succeeding it in a directed flow. Except that it is transparent and inherently more efficient via exact instructions. Versus the fundamental issue of probabilistic derivatives that get infinitely close to 100% accuracy that a universal function represents. For a Neural Network to be considered a comparably mirror to a Unified Turing Machine, would be a network that forgoes nodes not fully utilized within the weighted averaging sum of layers. A form of logical determination within the network itself that can disclude nodes from the weighted sums calculation. Would be the creation of some directed path that formalizes the output of the Neural Network based on the input. But that data does not exist and this framework, or rather Unified Turing Machines would be the path towards creating that data.

In addition if one accepts some logical determinism where we can disclude specific symbols that a classic turing machine would utilize. Noting that the quality selection uses semaphores versus type comparison of its inspiration. Then this system can be proven to halt via some specific configurations of concepts and their qualities. As the semaphore are the finite symbol reference table of a classical Turing Machine. Except here it is fully dynamic and may expand or reduce in its possible finite symbol selection at run time. And likewise represents the direct path through graph of potential possibilities in a blunt fashion.

We could limit use case like the its inspiration as a state machine to control form and functionality of some user interface, or client facing application. But in contrast, this system was designed with the whole computer system and internet in mind. Is capable of being location and form agnostic. And may be massively expanded and rewritten into other languages if they are able to satisfy the same dynamic requirements of this system. Thus as the graph computation model is purely agnostic to location of nodes and draws inspiration from "SmallTalk," via the passing of ActionStrategies via messages between cells/nodes. And is the spatial equivalent of a Neural Network, but without the need for the weight sum. But in contrast to its conception in 2018, it is now possible to use the same Neural Networks to decompose their functionality into a predictable safe compositions. That can further reinforce the same networks. As this is not to detract from that investment, but to provide a safe transparent mechanism of explainability.

This system may become more atomic over time to better represent the dynamics of language. But during this specific stage, this is a fine starting point towards the decomposition of the complexities of intelligence. As the weighted sum is still massively useful, when there is no direct obvious answer to find some solution to an input. But within this scope would be an entirely different type of Neural Network which does not currently exist. As that would be the generation of novelty over some averaged statistical gradient descent of known data. Would be finding new arrangements of concept and their qualities to find the next **Ah-Ha!**

## What this Methodology is Proposing: ABI
![Rick and Morty - Butter Bot](https://github.com/Phuire-Research/STRX/blob/main/butterBot.gif?raw=true)

What this methodology creates is the ability to formalize "Autonomous Baseline Intelligence," or ABI. And the purpose of creating this distinction is to categorization of a form of intelligence that is predictable and safe. Where even if we achieve some super intelligence, we should not have that super intelligence pass butter. But instead together we should create some baseline intelligence that is written in plain text, that is only capable enough to pass butter and can be proven to halt.

This would be the safest route of artificial intelligence deployment. Where we may have the truly intelligent models that might cross some threshold, be spared this type of realization. Further this would also allow us to design specialized chips to to run these intelligences within a limited specification. Going as far as printing the limited instruction sets that would formalize that aut intelligence itself onto the chips for additional safety.

## Release Disclosure
The internals of this application feature a design pattern released in 2018, ActionStrategy. This resulting framework and the creation of a Unified Turing Machine is the consequence of the complexity that this pattern imposes, despite its outward simplicity. Thus this framework simplifies the handling of its complex nature and solves the deficiencies of working with this pattern in preexisting frameworks capable of it. Noting that the Unified Turing Machine itself was an indirect discovery in order to handle such complexity.

This release has no license attached to provide a grace period to protect any potential patents that would result from the release of this repository. And should be considered to be a research release and work in progress. As it is the intention to fully open source this framework, host on npm, and translate into each programming language that might support it in the near future.

To some this might be the holy grail of training sound logic and reasoning into Neural Networks that is comparable to ourselves. For me, this is a framework that I have wanted to release as my self studied dissertation that has been on hold for 5 years. The Unified Turing Machine is my thesis, that it works the test, the documents shared alongside this repository the paper. Hope everyone enjoyed the Ai summer of 2023. This work is meant to enhance such, not take away in something that could be greater than the sums of its parts.

Be responsible, safe, and have fun!

# Safety Statement
Please note that while the ActionStrategy pattern is a fully dynamic method of programming. It runs into issues for the sake of its dynamics, traditionally classical methods of programming are transactional in nature and built for data entry. This runs into issues within our good enough implementations of our computer systems. Via branch prediction specifically. If not handled with halting in mind, and why I feel safe saying that the Unified Turing Machine solves the problem. The ActionStrategy pattern is fully capable of thrashing your applications memory via the creation of ghost actions, or duplicate actions that simply do not make sense. And would be seen as a hard requirement to be able to halt, for the machine to function within the branch prediction paradigm in the first place.

This is a large reason why I had pulled the approach and proof of concept of the original Unified Turing Machine at the beginning of 2023. But with the advent of the Stage paradigm, such asserts a hard correction to prevent the creation of ghost duplicate actions, as well as prevent action overflow. Thus if one is training a Neural Network on an approach similar to ActionStrategy pattern to improve reasoning and logic, be mindful that there is runaway potential if not handled with care. The beginning of this year on my part was dedicated to solving the zero day of some party who was utilizing this approach as a trade secret. With this release, is the bundled experience of working with the ActionStrategy pattern over the last 5 years and attempting to find the safest implementation.

So while this approach can be considered as Holy Grail. Be mindful of India Jones and what cup the grail turned out to be.